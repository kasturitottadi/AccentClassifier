{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üîß MFCC Model - Fixed Retraining\n",
        "\n",
        "This notebook fixes the issue where model predicts only Malayalam.\n",
        "\n",
        "**Fixes:**\n",
        "- Proper class balancing\n",
        "- Better training parameters\n",
        "- Validation checks\n",
        "- Debug outputs"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "PROJECT_DIR = '/content/drive/MyDrive/IndicAccent_Project'\n",
        "os.chdir(PROJECT_DIR)\n",
        "print(f'‚úÖ Working directory: {os.getcwd()}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets==3.0.1 torch torchaudio librosa soundfile scikit-learn matplotlib tqdm\n",
        "print('‚úÖ Dependencies installed!')"
      ],
      "metadata": {
        "id": "install"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pickle\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Device: {device}')\n",
        "\n",
        "label_map = {\n",
        "    0: \"Telugu\",\n",
        "    1: \"Tamil\",\n",
        "    2: \"Malayalam\",\n",
        "    3: \"Kannada\",\n",
        "    4: \"Hindi\",\n",
        "    5: \"Gujarati\"\n",
        "}"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Step 1: Load and Check Data"
      ],
      "metadata": {
        "id": "load-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load merged MFCC features\n",
        "files = sorted(glob.glob(f\"{PROJECT_DIR}/mfcc_chunks/*.pkl\"))\n",
        "print(f'Found {len(files)} chunk files')\n",
        "\n",
        "X_all, y_all = [], []\n",
        "\n",
        "for file in files:\n",
        "    with open(file, \"rb\") as f:\n",
        "        data = pickle.load(f)\n",
        "        X_all.append(data[\"X\"])\n",
        "        y_all.append(data[\"y\"])\n",
        "\n",
        "X_all = np.vstack(X_all)\n",
        "y_all = np.concatenate(y_all)\n",
        "\n",
        "print(f'\\n‚úÖ Data loaded')\n",
        "print(f'   Features: {X_all.shape}')\n",
        "print(f'   Labels: {y_all.shape}')\n",
        "\n",
        "# CHECK CLASS DISTRIBUTION\n",
        "print('\\nüìä Class Distribution:')\n",
        "for label in range(6):\n",
        "    count = np.sum(y_all == label)\n",
        "    print(f'   {label} ({label_map[label]:12}): {count:4d} samples ({count/len(y_all)*100:.1f}%)')\n",
        "\n",
        "# Check for issues\n",
        "if len(np.unique(y_all)) != 6:\n",
        "    print('\\n‚ö†Ô∏è WARNING: Not all 6 classes present in data!')\n",
        "else:\n",
        "    print('\\n‚úÖ All 6 classes present')"
      ],
      "metadata": {
        "id": "load-data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† Step 2: Define Model"
      ],
      "metadata": {
        "id": "model-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MFCCModel(nn.Module):\n",
        "    def __init__(self, input_dim=80, num_classes=6):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "print('‚úÖ Model defined')"
      ],
      "metadata": {
        "id": "model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîÑ Step 3: Prepare Data with Stratification"
      ],
      "metadata": {
        "id": "prep-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split with stratification (ensures balanced classes)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_all, y_all, \n",
        "    test_size=0.2, \n",
        "    random_state=42, \n",
        "    stratify=y_all  # IMPORTANT: keeps class balance\n",
        ")\n",
        "\n",
        "print(f'Train samples: {len(X_train)}')\n",
        "print(f'Val samples: {len(X_val)}')\n",
        "\n",
        "# Check train distribution\n",
        "print('\\nTrain distribution:')\n",
        "for label in range(6):\n",
        "    count = np.sum(y_train == label)\n",
        "    print(f'   {label_map[label]:12}: {count:4d} ({count/len(y_train)*100:.1f}%)')\n",
        "\n",
        "# Check val distribution\n",
        "print('\\nValidation distribution:')\n",
        "for label in range(6):\n",
        "    count = np.sum(y_val == label)\n",
        "    print(f'   {label_map[label]:12}: {count:4d} ({count/len(y_val)*100:.1f}%)')\n",
        "\n",
        "# Dataset class\n",
        "class MFCCDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        return self.X[i], self.y[i]\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(MFCCDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(MFCCDataset(X_val, y_val), batch_size=64)\n",
        "\n",
        "print('\\n‚úÖ Data loaders ready')"
      ],
      "metadata": {
        "id": "prep-data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèãÔ∏è Step 4: Train with Monitoring"
      ],
      "metadata": {
        "id": "train-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize\n",
        "model = MFCCModel().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "print('‚úÖ Model initialized')\n",
        "print(f'   Parameters: {sum(p.numel() for p in model.parameters()):,}')\n",
        "\n",
        "# Training loop with detailed monitoring\n",
        "NUM_EPOCHS = 20\n",
        "best_val_acc = 0.0\n",
        "\n",
        "print(f'\\nTraining for {NUM_EPOCHS} epochs...\\n')\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Training\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    \n",
        "    for feats, labels in train_loader:\n",
        "        feats, labels = feats.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        preds = model(feats)\n",
        "        loss = loss_fn(preds, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "        train_correct += (preds.argmax(dim=1) == labels).sum().item()\n",
        "        train_total += labels.size(0)\n",
        "    \n",
        "    train_loss /= len(train_loader)\n",
        "    train_acc = train_correct / train_total\n",
        "    \n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    val_loss = 0.0\n",
        "    \n",
        "    # Track per-class accuracy\n",
        "    class_correct = [0] * 6\n",
        "    class_total = [0] * 6\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for feats, labels in val_loader:\n",
        "            feats, labels = feats.to(device), labels.to(device)\n",
        "            preds = model(feats)\n",
        "            loss = loss_fn(preds, labels)\n",
        "            val_loss += loss.item()\n",
        "            \n",
        "            pred_labels = preds.argmax(dim=1)\n",
        "            val_correct += (pred_labels == labels).sum().item()\n",
        "            val_total += labels.size(0)\n",
        "            \n",
        "            # Per-class accuracy\n",
        "            for i in range(len(labels)):\n",
        "                label = labels[i].item()\n",
        "                class_total[label] += 1\n",
        "                if pred_labels[i] == labels[i]:\n",
        "                    class_correct[label] += 1\n",
        "    \n",
        "    val_loss /= len(val_loader)\n",
        "    val_acc = val_correct / val_total\n",
        "    \n",
        "    # Save best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), f\"{PROJECT_DIR}/mfcc_best_model_fixed.pt\")\n",
        "        best_marker = \" üåü BEST\"\n",
        "    else:\n",
        "        best_marker = \"\"\n",
        "    \n",
        "    print(f\"Epoch {epoch+1:2d}/{NUM_EPOCHS} | \"\n",
        "          f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}{best_marker}\")\n",
        "    \n",
        "    # Show per-class accuracy every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(\"  Per-class validation accuracy:\")\n",
        "        for i in range(6):\n",
        "            if class_total[i] > 0:\n",
        "                acc = class_correct[i] / class_total[i]\n",
        "                print(f\"    {label_map[i]:12}: {acc:.3f} ({class_correct[i]}/{class_total[i]})\")\n",
        "        print()\n",
        "\n",
        "print(f'\\n‚úÖ Training complete!')\n",
        "print(f'   Best validation accuracy: {best_val_acc:.4f} ({best_val_acc*100:.2f}%)')"
      ],
      "metadata": {
        "id": "train"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß™ Step 5: Test Model Predictions"
      ],
      "metadata": {
        "id": "test-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best model\n",
        "model.load_state_dict(torch.load(f\"{PROJECT_DIR}/mfcc_best_model_fixed.pt\"))\n",
        "model.eval()\n",
        "\n",
        "print(\"üß™ Testing model with random inputs...\\n\")\n",
        "\n",
        "# Test 1: Random noise\n",
        "print(\"Test 1: Random noise (should give varied predictions)\")\n",
        "for i in range(5):\n",
        "    random_input = torch.randn(1, 80).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(random_input)\n",
        "        pred = output.argmax().item()\n",
        "        prob = torch.softmax(output, dim=1)[0][pred].item()\n",
        "    print(f\"  {i+1}. Predicted: {label_map[pred]:12} ({prob*100:.1f}%)\")\n",
        "\n",
        "# Test 2: Real validation samples\n",
        "print(\"\\nTest 2: Real validation samples\")\n",
        "for i in range(5):\n",
        "    idx = np.random.randint(0, len(X_val))\n",
        "    sample = torch.tensor(X_val[idx], dtype=torch.float32).unsqueeze(0).to(device)\n",
        "    true_label = y_val[idx]\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(sample)\n",
        "        pred = output.argmax().item()\n",
        "        prob = torch.softmax(output, dim=1)[0][pred].item()\n",
        "    \n",
        "    match = \"‚úÖ\" if pred == true_label else \"‚ùå\"\n",
        "    print(f\"  {i+1}. True: {label_map[true_label]:12} | Pred: {label_map[pred]:12} ({prob*100:.1f}%) {match}\")\n",
        "\n",
        "print(\"\\n‚úÖ If you see varied predictions above, model is working!\")\n",
        "print(\"   If it always predicts Malayalam, there's still an issue.\")"
      ],
      "metadata": {
        "id": "test"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üíæ Step 6: Save Final Model"
      ],
      "metadata": {
        "id": "save-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save with clear name\n",
        "torch.save(model.state_dict(), f\"{PROJECT_DIR}/mfcc_best_model.pt\")\n",
        "\n",
        "print('‚úÖ Model saved!')\n",
        "print(f'   Location: {PROJECT_DIR}/mfcc_best_model.pt')\n",
        "print(f'   Backup: {PROJECT_DIR}/mfcc_best_model_fixed.pt')\n",
        "print('\\nüéâ Now use this model in your Gradio demo!')"
      ],
      "metadata": {
        "id": "save"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
